# Project 4 â€” Multimodal RAG

> **Go beyond plain text.** This project builds a Retrieval-Augmented
> Generation system that understands **text**, **images**, and **tables**
> inside PDF documents.

---

## Architecture

```
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   PDF File   â”‚
                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ Multimodal      â”‚
                       â”‚ Parser          â”‚
                       â””â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”˜
                          â”‚     â”‚     â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â–¼                â–¼                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Text       â”‚  â”‚ Images     â”‚  â”‚ Tables       â”‚
        â”‚ Chunks     â”‚  â”‚ (PNG)      â”‚  â”‚ (CSV)        â”‚
        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚               â”‚                 â”‚
              â”‚         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
              â”‚         â”‚ Vision LLM â”‚   â”‚ LLM Describe â”‚
              â”‚         â”‚ â†’ Caption  â”‚   â”‚ â†’ Summary    â”‚
              â”‚         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚               â”‚                 â”‚
        â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
        â”‚ Text       â”‚ â”‚ Image      â”‚  â”‚ Table        â”‚
        â”‚ FAISS      â”‚ â”‚ FAISS      â”‚  â”‚ FAISS        â”‚
        â”‚ Index      â”‚ â”‚ Index      â”‚  â”‚ Index        â”‚
        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
              â”‚               â”‚                 â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”       â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–¼       â–¼       â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚     Query Router        â”‚
                â”‚  "Which indexes to      â”‚
                â”‚   search?"              â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Multi-Retriever       â”‚
                â”‚   Merge + Rank          â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Generator (LLM)       â”‚
                â”‚   â†’ Final Answer        â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## What Is "Multimodal" RAG?

Traditional RAG only handles text. But real-world documents contain much
more:

| Modality | Examples | What text-only RAG misses |
|----------|---------|--------------------------|
| **Text** | Paragraphs, headings, lists | *(handled)* |
| **Images** | Charts, diagrams, photos, screenshots | A bar chart showing revenue trends is invisible to text search |
| **Tables** | Financial data, comparison matrices, specs | Row/column structure is lost when flattened to plain text |
| **Cross-modal** | "Compare the chart on page 3 with Table 2" | Requires reasoning across modalities |

### Examples of questions this project can answer

- *"What trend does the line chart on page 5 show?"* â€” needs image
  understanding
- *"What was Q3 revenue?"* â€” needs table search
- *"Summarize the introduction and relate it to Figure 1"* â€” needs text +
  image

---

## Model Comparison

| Capability | OpenAI (GPT-4o) | Ollama (local) |
|------------|-----------------|----------------|
| Text generation | âœ… Excellent | âœ… Good (llama3) |
| Image captioning | âœ… GPT-4o vision | âœ… LLaVA model |
| Table description | âœ… Excellent | âœ… Good |
| Cost | ğŸ’° Pay-per-token | ğŸ†“ Free |
| Privacy | â˜ï¸ Cloud | ğŸ”’ Local |
| Speed | âš¡ Fast | ğŸ¢ Depends on hardware |

---

## Cost Considerations

| Operation | Approximate Cost (GPT-4o) |
|-----------|--------------------------|
| Parse PDF | Free (local library) |
| Caption 1 image | ~$0.01â€“0.03 |
| Describe 1 table | ~$0.001â€“0.005 |
| Embed chunks | Free (local model) |
| 1 query + answer | ~$0.01â€“0.03 |

**Cost-saving tips:**
- Use Ollama for development (free, runs locally)
- Cache image captions and table descriptions (they don't change)
- Use the query router to avoid searching unnecessary indexes
- Use `all-MiniLM-L6-v2` for embeddings (free, fast, local)

---

## Setup

### Prerequisites

- Python 3.10+
- (Optional) [Ollama](https://ollama.ai) for free local models

### Installation

```bash
# 1. Navigate to the project directory
cd 04-multimodal-rag

# 2. Create a virtual environment
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Configure environment
cp .env.example .env
# Edit .env and add your OpenAI API key (or set USE_OLLAMA=true)
```

### If Using Ollama (Free, Local)

```bash
# Install Ollama from https://ollama.ai, then:
ollama pull llama3        # text model
ollama pull llava         # vision model (for image captioning)

# In your .env:
USE_OLLAMA=true
OLLAMA_MODEL=llama3
VISION_MODEL=llava
```

---

## Usage

### 1. Ingest a PDF Document

```bash
python main.py --pdf data/sample_docs/your_document.pdf
```

This will:
- Extract text, images, and tables from the PDF
- Caption each image with a vision model
- Describe each table with an LLM
- Build three FAISS indexes (text, image, table)

### 2. Ask Questions (Interactive Mode)

```bash
python main.py
```

```
You: What does the chart on page 3 show?
Assistant: The chart on page 3 is a bar chart showing quarterly revenue...

You: What was the total revenue in Q3?
Assistant: According to the financial table, Q3 revenue was $142M...

You: quit
```

### 3. Single Query Mode

```bash
python main.py --query "Summarize the key findings"
```

---

## How to Add Your Own Documents

1. Place your PDF file(s) in `data/sample_docs/`
2. Run `python main.py --pdf data/sample_docs/your_file.pdf`
3. Start asking questions with `python main.py`

**Supported formats:** PDF files with any combination of text, images, and
tables.

**Tips for best results:**
- Scanned PDFs (image-only) need OCR â€” consider adding `pytesseract`
- High-resolution PDFs yield better image extraction
- Tables with clear grid lines are extracted more reliably

---

## Project Structure

```
04-multimodal-rag/
â”œâ”€â”€ main.py                    # Entry point â€” ingest & query
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .env.example               # Configuration template
â”œâ”€â”€ README.md                  # This file
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample_docs/           # Put your PDFs here
â”‚   â”œâ”€â”€ extracted/
â”‚   â”‚   â”œâ”€â”€ images/            # Extracted images (PNG)
â”‚   â”‚   â””â”€â”€ tables/            # Extracted tables (CSV)
â”‚   â””â”€â”€ indexes/               # FAISS indexes (auto-created)
â”‚       â”œâ”€â”€ text_index/
â”‚       â”œâ”€â”€ image_index/
â”‚       â””â”€â”€ table_index/
â””â”€â”€ src/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ multimodal_parser.py   # PDF â†’ text + images + tables
    â”œâ”€â”€ text_indexer.py        # Chunk & embed text â†’ FAISS
    â”œâ”€â”€ image_processor.py     # Image â†’ caption via vision LLM
    â”œâ”€â”€ image_indexer.py       # Caption embeddings â†’ FAISS
    â”œâ”€â”€ table_processor.py     # Table â†’ NL description via LLM
    â”œâ”€â”€ table_indexer.py       # Description embeddings â†’ FAISS
    â”œâ”€â”€ query_router.py        # Classify query â†’ route to indexes
    â”œâ”€â”€ multi_retriever.py     # Search + merge + rank results
    â””â”€â”€ generator.py           # Generate final answer from context
```
