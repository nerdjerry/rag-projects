# LLM Provider Configuration
# Option 1: OpenAI (requires API key)
OPENAI_API_KEY=your-openai-api-key-here

# Option 2: Ollama (free, local â€” install from https://ollama.ai)
# Set USE_OLLAMA=true to use local models instead of OpenAI
USE_OLLAMA=false
OLLAMA_MODEL=llama3

# RAG Configuration
CHUNK_SIZE=500
CHUNK_OVERLAP=50
TOP_K=3
